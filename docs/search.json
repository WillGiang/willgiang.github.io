[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m an imaging scientist who works with advanced light microscopes. This blog will cover sample preparation, acquisition, and image analysis/processing–especially in the context of labs and core facilities."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Image restoration with deep learning\n\n\n\n\n\n\n\nmicroscopy\n\n\nanalysis\n\n\ndeep-learning\n\n\n\n\nImage restoration with deep learning as used in Architecture and dynamics of a desmosome–endoplasmic reticulum complex\n\n\n\n\n\n\nAug 3, 2023\n\n\nWilliam Giang\n\n\n\n\n\n\n  \n\n\n\n\nEducational Resources and Tools\n\n\n\n\n\n\n\nsample-prep\n\n\nmicroscopy\n\n\nanalysis\n\n\nresources\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2023\n\n\nWilliam Giang\n\n\n\n\n\n\n  \n\n\n\n\nSpinning Disk Confocal PSFs with PSFmodels\n\n\n\n\n\n\n\nPython\n\n\nPSF\n\n\nspinning-disk-confocal\n\n\n\n\n\n\n\n\n\n\n\nJun 4, 2023\n\n\nWilliam Giang\n\n\n\n\n\n\n  \n\n\n\n\nVisualization Options in Fiji\n\n\n\n\n\n\n\nvisualization\n\n\nFiji\n\n\nImageJ\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2022\n\n\nWilliam Giang\n\n\n\n\n\n\n  \n\n\n\n\nInsights into Spectra-Physics’ InSight DeepSee\n\n\n\n\n\n\n\nPython\n\n\nanalysis\n\n\nlasers\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2022\n\n\nWilliam Giang\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2022\n\n\nWilliam Giang\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-09-25_Insights-into-DeepSee/09-2022_InSight_DeepSee.html",
    "href": "posts/2022-09-25_Insights-into-DeepSee/09-2022_InSight_DeepSee.html",
    "title": "Insights into Spectra-Physics’ InSight DeepSee",
    "section": "",
    "text": "We thought the Nikon A1R MP’s laser system, the Spectra-Physics InSight DeepSee, was in need of repair. After contacting the service engineer for Spectra-Physics, we learned two laser diodes were already replaced with a bill of $30k. We were also warned that the laser power had been reduced, but otherwise the DeepSee should be functional.\n\nThe liquid in the chiller unit has been flushed and replaced with coolant.\nAfter turning on the microscope and laser systems, it took several days for the laser’s humidity to reach acceptable levels\nThe power output has been reduced\n\n\n\n\nImage of A1plus MP GUI\n\n\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/2022-09-25_Insights-into-DeepSee/09-2022_InSight_DeepSee.html#overview",
    "href": "posts/2022-09-25_Insights-into-DeepSee/09-2022_InSight_DeepSee.html#overview",
    "title": "Insights into Spectra-Physics’ InSight DeepSee",
    "section": "",
    "text": "We thought the Nikon A1R MP’s laser system, the Spectra-Physics InSight DeepSee, was in need of repair. After contacting the service engineer for Spectra-Physics, we learned two laser diodes were already replaced with a bill of $30k. We were also warned that the laser power had been reduced, but otherwise the DeepSee should be functional.\n\nThe liquid in the chiller unit has been flushed and replaced with coolant.\nAfter turning on the microscope and laser systems, it took several days for the laser’s humidity to reach acceptable levels\nThe power output has been reduced\n\n\n\n\nImage of A1plus MP GUI\n\n\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/2022-09-25_Insights-into-DeepSee/09-2022_InSight_DeepSee.html#how-long-does-the-insight-deepsee-need-to-effectively-warm-up",
    "href": "posts/2022-09-25_Insights-into-DeepSee/09-2022_InSight_DeepSee.html#how-long-does-the-insight-deepsee-need-to-effectively-warm-up",
    "title": "Insights into Spectra-Physics’ InSight DeepSee",
    "section": "How long does the InSight DeepSee need to effectively warm up?",
    "text": "How long does the InSight DeepSee need to effectively warm up?\nSept 20: Turned on all scope components and noticed humidity was too high, so I started logging it\n\n\nCode\nhumidity_csv = \"Time_since_DeepSee_turn_on.csv\"\nhumidity_df = pd.read_csv(humidity_csv)\n\nhumidity_plot = sns.scatterplot(data = humidity_df,\n                                x = \"Time [Minutes]\",\n                                y = \"Relative Humidity [%]\",\n                               )\n\nhumidity_plot.set_title(\"Four days for humidity to stabilize from start-up\")\nhumidity_plot.set_xlim(0, 4500)\n\n\n(0.0, 4500.0)"
  },
  {
    "objectID": "posts/2022-09-25_Insights-into-DeepSee/09-2022_InSight_DeepSee.html#how-much-power-did-we-lose-as-a-function-of-wavelength",
    "href": "posts/2022-09-25_Insights-into-DeepSee/09-2022_InSight_DeepSee.html#how-much-power-did-we-lose-as-a-function-of-wavelength",
    "title": "Insights into Spectra-Physics’ InSight DeepSee",
    "section": "How much power did we lose as a function of wavelength?",
    "text": "How much power did we lose as a function of wavelength?\n\nDigitized the theoretical tuning power from the manual\nThere also appears to be a warmup time after turning emission ON\nSevere drop in power when laser is tuned above 1000nm\n\n\n\nCode\ndata_csv = \"2022-09-23_laser-power-vs-wavelength_with-theoretical.csv\"\ndf = pd.read_csv(data_csv)\n\npalette = sns.color_palette(\"mako_r\", 5)\nsns.set_theme(style=\"whitegrid\")\n\ng = sns.scatterplot(data = df,\n                    x = \"Wavelength [nm]\",\n                    y = \"Power [mW]\",\n                    hue = \"Replicate\",\n                    style = \"Replicate\",\n                    palette = palette,\n                   )\n\ng.set_title(\"InSight DeepSee far from spec \\nat $\\lambda$ &gt; 1000nm\")\ng.set_xlim(700, 1100)\ng.set_ylim(-20, 1400)\n\n\n(-20.0, 1400.0)"
  },
  {
    "objectID": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html",
    "href": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html",
    "title": "Visualization Options in Fiji",
    "section": "",
    "text": "A curated subset of visualization options within Fiji for labmates.\nExample dataset: single-channel z-stack with fluorescently tagged keratin-14\nWe’ll cover:\n\nA common “solution” for seeing fainter structures\nA better solution using gamma for seeing fainter structures\nColor-coding by orientation\nColor-coding by radiality\nColor-coding by depth\n\n\n\nFirst, we’ll load a max intensity projection with brightness & contrast settings chosen such that they are pretty much at the min and max values of the image\nopen(\"C:/Users/will/Documents/2022-11-06_keratin-visualization/MAX_00-keratin-crop_MIP_130_14000.tif\");\norig_name = getTitle();\nsetMinAndMax(130, 14000);\n\nThis 16-bit image has a fair amount of dynamic range, so it’s tough to make out the fainter keratin filaments.\nOne common “solution” is by reducing the maximum value within the Brightness and Contrast window, but then the brighter structures appear blown out.\nrun(\"Duplicate...\", \" \");\nsetMinAndMax(130, 3100);\n\n\n\n\nA better solution is to use gamma1 for adjusting the LUT.\nLet’s make use of LUTs2 that incorporate different gamma values.\nFrom left to right: gamma = 0.25, 0.50, 0.75\nsetMinAndMax(130, 14000);\n\nfor (i = 25; i &lt; 100;i=i+25){\n    run(\"Duplicate...\", \" \");\n    run(\"JDM Grays g=0.\" + i + \" \");\n}\n  \n\n\n\nHowever, what if you want a gamma of 0.6?\nUsing the Visualization Toolset from @kWolbachia, you can freely adjust the gamma on the LUT itself.\nBy holding the ctrl key and then dragging the mouse side to side, you can easily and quickly find the optimal gamma setting.\n\n\n\nUsing OrientationJ, images can be colored by local orientation and coherency.\nLeft: Original greyscale\nRight: Colored in HSB mode where hue is orientation, saturation is coherency, and brightness comes from original image\nselectWindow(orig_name);\nrun(\"Duplicate...\", \" \");\nrun(\"OrientationJ Analysis\", \"tensor=2.0 gradient=0 color-survey=on hsb=on hue=Orientation sat=Coherency bri=Original-Image radian=off \");\nsetMinAndMax(0, 100);\n \n\n\n\nBuilding on OrientationJ, @katpyxa created a macro for splitting an image into radial and non-radial components.\nLeft: Original greyscale\nRight: Radial (magenta) and non-radial (cyan) components\n \n\n\n\nImageJ/Fiji has a “Temporal-Color Code” feature which works fine if eventually you want a Z-projection.\n@katpyxa has a nice plugin for doing depth color coding without Z-projections and with bonus options.\nAstute readers will notice that this coverslip was slightly tilted!\nImage: Example of Temporal-Color Code with the Fire LUT and increased contrast\nopen(\"C:/Users/will/Documents/2022-11-06_keratin-visualization/00-keratin-crop.tif\");\nrun(\"Temporal-Color Code\", \"lut=Fire start=1 end=18\");\nsetMinAndMax(0, 100);"
  },
  {
    "objectID": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#max-intensity-projection-typical",
    "href": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#max-intensity-projection-typical",
    "title": "Visualization Options in Fiji",
    "section": "",
    "text": "First, we’ll load a max intensity projection with brightness & contrast settings chosen such that they are pretty much at the min and max values of the image\nopen(\"C:/Users/will/Documents/2022-11-06_keratin-visualization/MAX_00-keratin-crop_MIP_130_14000.tif\");\norig_name = getTitle();\nsetMinAndMax(130, 14000);\n\nThis 16-bit image has a fair amount of dynamic range, so it’s tough to make out the fainter keratin filaments.\nOne common “solution” is by reducing the maximum value within the Brightness and Contrast window, but then the brighter structures appear blown out.\nrun(\"Duplicate...\", \" \");\nsetMinAndMax(130, 3100);"
  },
  {
    "objectID": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#adjusting-gamma-via-a-look-up-table-lut",
    "href": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#adjusting-gamma-via-a-look-up-table-lut",
    "title": "Visualization Options in Fiji",
    "section": "",
    "text": "A better solution is to use gamma1 for adjusting the LUT.\nLet’s make use of LUTs2 that incorporate different gamma values.\nFrom left to right: gamma = 0.25, 0.50, 0.75\nsetMinAndMax(130, 14000);\n\nfor (i = 25; i &lt; 100;i=i+25){\n    run(\"Duplicate...\", \" \");\n    run(\"JDM Grays g=0.\" + i + \" \");\n}"
  },
  {
    "objectID": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#adjusting-gamma-using-visualization-toolset",
    "href": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#adjusting-gamma-using-visualization-toolset",
    "title": "Visualization Options in Fiji",
    "section": "",
    "text": "However, what if you want a gamma of 0.6?\nUsing the Visualization Toolset from @kWolbachia, you can freely adjust the gamma on the LUT itself.\nBy holding the ctrl key and then dragging the mouse side to side, you can easily and quickly find the optimal gamma setting."
  },
  {
    "objectID": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#color-coding-by-orientation",
    "href": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#color-coding-by-orientation",
    "title": "Visualization Options in Fiji",
    "section": "",
    "text": "Using OrientationJ, images can be colored by local orientation and coherency.\nLeft: Original greyscale\nRight: Colored in HSB mode where hue is orientation, saturation is coherency, and brightness comes from original image\nselectWindow(orig_name);\nrun(\"Duplicate...\", \" \");\nrun(\"OrientationJ Analysis\", \"tensor=2.0 gradient=0 color-survey=on hsb=on hue=Orientation sat=Coherency bri=Original-Image radian=off \");\nsetMinAndMax(0, 100);"
  },
  {
    "objectID": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#color-coding-by-radialitynon-radiality",
    "href": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#color-coding-by-radialitynon-radiality",
    "title": "Visualization Options in Fiji",
    "section": "",
    "text": "Building on OrientationJ, @katpyxa created a macro for splitting an image into radial and non-radial components.\nLeft: Original greyscale\nRight: Radial (magenta) and non-radial (cyan) components"
  },
  {
    "objectID": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#color-coding-by-depth",
    "href": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#color-coding-by-depth",
    "title": "Visualization Options in Fiji",
    "section": "",
    "text": "ImageJ/Fiji has a “Temporal-Color Code” feature which works fine if eventually you want a Z-projection.\n@katpyxa has a nice plugin for doing depth color coding without Z-projections and with bonus options.\nAstute readers will notice that this coverslip was slightly tilted!\nImage: Example of Temporal-Color Code with the Fire LUT and increased contrast\nopen(\"C:/Users/will/Documents/2022-11-06_keratin-visualization/00-keratin-crop.tif\");\nrun(\"Temporal-Color Code\", \"lut=Fire start=1 end=18\");\nsetMinAndMax(0, 100);"
  },
  {
    "objectID": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#footnotes",
    "href": "posts/2022-11-06_Visualization-in-Fiji/2022-11-06_Visualization-in-Fiji.html#footnotes",
    "title": "Visualization Options in Fiji",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee here for a nice tweetorial on gamma by @loicaroyer↩︎\nThanks to JDM_LUTs and NeuroCyto_LUTs!↩︎"
  },
  {
    "objectID": "posts/2023-06-04_Spinning-Disk-Confocal-PSFs/Spinning-Disk-Confocal-PSFs-with-psfmodels.html",
    "href": "posts/2023-06-04_Spinning-Disk-Confocal-PSFs/Spinning-Disk-Confocal-PSFs-with-psfmodels.html",
    "title": "Spinning Disk Confocal PSFs with PSFmodels",
    "section": "",
    "text": "Obtaining an accurate point spread function (PSF) is vital for good deconvolution.\nHere’s how to obtain the pinhole_au parameter for generating a confocal PSF in Talley Lambert’s PSFmodels."
  },
  {
    "objectID": "posts/2023-06-04_Spinning-Disk-Confocal-PSFs/Spinning-Disk-Confocal-PSFs-with-psfmodels.html#motivation",
    "href": "posts/2023-06-04_Spinning-Disk-Confocal-PSFs/Spinning-Disk-Confocal-PSFs-with-psfmodels.html#motivation",
    "title": "Spinning Disk Confocal PSFs with PSFmodels",
    "section": "",
    "text": "Obtaining an accurate point spread function (PSF) is vital for good deconvolution.\nHere’s how to obtain the pinhole_au parameter for generating a confocal PSF in Talley Lambert’s PSFmodels."
  },
  {
    "objectID": "posts/2023-06-04_Spinning-Disk-Confocal-PSFs/Spinning-Disk-Confocal-PSFs-with-psfmodels.html#theory",
    "href": "posts/2023-06-04_Spinning-Disk-Confocal-PSFs/Spinning-Disk-Confocal-PSFs-with-psfmodels.html#theory",
    "title": "Spinning Disk Confocal PSFs with PSFmodels",
    "section": "Theory",
    "text": "Theory\nA measure of confocality (in Airy units) is the ratio between the back projected pinhole radius and the radius of the Airy disk.\nSince the back projected pinhole radius (R_{BP}) is the size of the pinhole radius projected on the sample plane, it can be calculated with the pinhole radius (R_{PR}) divided by the total magnification between the pinhole(s) and the sample, which includes the objective’s magnification (M_{O}) and other potential sources of intermediate magnification (M_{I})\n R_{BP} = {R_{PR} \\over M_{O} * M_{I}} \nThe radius of an Airy disk (R_{A}) is equivalent to Rayleigh’s lateral resolution criterion which is the product of 0.61 and wavelength (\\lambda) divided by the numerical aperture (NA)\n R_{A} = 0.61 {\\lambda \\over NA }"
  },
  {
    "objectID": "posts/2023-06-04_Spinning-Disk-Confocal-PSFs/Spinning-Disk-Confocal-PSFs-with-psfmodels.html#confocality-with-yokogawa-csu-x1",
    "href": "posts/2023-06-04_Spinning-Disk-Confocal-PSFs/Spinning-Disk-Confocal-PSFs-with-psfmodels.html#confocality-with-yokogawa-csu-x1",
    "title": "Spinning Disk Confocal PSFs with PSFmodels",
    "section": "Confocality with Yokogawa CSU-X1",
    "text": "Confocality with Yokogawa CSU-X1\nWith a physical pinhole radius of 25 microns, the Yokogawa CSU-X1 spinning disk unit is optimized for high resolution live-cell imaging, so we should expect a smaller confocality value when imaging with a high resolution objective than with a lower resolution objective.\nLet’s compare the confocality between two objectives (100x/1.49 and 20x/0.75) when imaging EGFP (emission peak wavelength at 509nm).\n\n\n\n\n\n\n\n\n\n\n\nObjective Mag\nObjective NA\n\\lambda (um)\nBack Projected Pinhole Radius (um)\nAiry Disk Radius (um)\nConfocality (Airy units)\n\n\n\n\n20x\n0.75\n0.509\n1.25\n0.414\n3\n\n\n100x\n1.49\n0.509\n0.166\n0.208\n1.2\n\n\n\n\n\nCode\nimport psfmodels as psfm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import PowerNorm\n\ndef backProjectedPinholeRadius(PinholeRadius, MagObjective, MagIntermediate=1):\n    \"\"\"\n    Return the back projected pinhole radius for a spinning disk confocal unit.\n    \n    Parameters\n    ----------\n    PinholeRadius : float\n        Physical radius of the pinhole\n    MagObjective : int\n        Magnification of the objective\n    MagIntermediate : float\n        Other magnification between the spinning disk and sample\n        \n    Returns\n    -------\n    float\n        The `pinholeRadius` divided by both `MagObjective` and `MagIntermediate`\n    \n    Examples\n    --------\n    &gt;&gt;&gt; backProjectedPinholeRadius(25, 100)\n    0.25\n    &gt;&gt;&gt; backProjectedPinholeRadius(25, 100, 1.5)\n    0.16666666666666666\n    \"\"\"\n    return PinholeRadius / (MagObjective*MagIntermediate)\n\ndef airyDiskRadius(wavelength, NA):\n    \"\"\"\n    Return the radius of an Airy Disk given a wavelength and numerical aperture.\n    \n    Parameters\n    ----------\n    wavelength : float\n        Wavelength\n    NA : float\n        Numerical aperture of the objective\n    \n    Returns\n    -------\n    float\n        0.61 multiplied by `wavelength` and divided by `NA`\n        \n    Examples\n    --------\n    &gt;&gt;&gt; airyDiskRadius(509, 1.49)\n    208.38\n    &gt;&gt;&gt; airyDiskRadius(509, 0.75)\n    413.99\n    \"\"\"\n    return 0.61 * wavelength / NA\n\ndef confocality(BackProjectedPinholeRadius, AiryDiskRadius):\n    \"\"\"\n    Return the confocality (in Airy Units) for a spinning disk confocal\n    \n    Parameters\n    ----------\n    BackProjectedPinholeRadius : float\n        The pinhole radius projected on the sample plane\n    AiryDiskRadius : float\n        The radius of an Airy Disk (also equivalent to Rayleigh's lateral resolution)\n    \n    Returns\n    -------\n    float\n        The `BackProjectedPinholeRadius` divided by the `AiryDiskRadius`\n    \n    Examples\n    --------\n    &gt;&gt;&gt; confocality(0.25, 0.208)\n    1.2\n    &gt;&gt;&gt; confocality(1.25, 0.6)\n    2.1\n    \"\"\"\n    return BackProjectedPinholeRadius/AiryDiskRadius\n\ndef plotConfocalPSF(params):\n    \"\"\"\n    Returns the confocal PSF while plotting lateral and axial views.\n    \"\"\"\n    nz = params[\"nx\"]\n    \n    ConfocalPSF = psfm.confocal_psf(**params)\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    ax1.imshow(ConfocalPSF[nz//2], norm = PowerNorm(gamma=0.4))\n    ax2.imshow(ConfocalPSF[:,params[\"nx\"]//2], norm = PowerNorm(gamma=0.4))\n    \n    ax1.set_title(\"lateral\")\n    ax2.set_title(\"axial\")\n    \n    figtitle1 = \"NA:{} | pinhole_au:{} | em_wvl:{}\\n\".format(\n        params[\"NA\"],\n        round(params[\"pinhole_au\"], 2),\n        params[\"em_wvl\"],\n    )\n    figtitle2 = \"sample RI:{} | immersion medium RI:{}\\n\".format(\n        params[\"ns\"],\n        params[\"ni\"]\n    )\n    figtitle3 = \"depth:{} | model:{}\".format(\n        params[\"pz\"],\n        params[\"model\"],\n    )\n    \n    fig.suptitle(figtitle1 + figtitle2 + figtitle3\n        )\n    \n    return ConfocalPSF\n\n\n\nOptimal imaging with an oil immersion objective at the coverslip\nFirst, let’s consider an optimal PSF where the location is right at the coverslip and the sample is mounted in an RI-matched solution.\n\n\nCode\nex_wvl = 0.488\nem_wvl = 0.509\npinhole_radius = 25\nmag_objective = 100\nNA = 1.49\npinhole_radius_BP = backProjectedPinholeRadius(pinhole_radius, mag_objective)\nairy_disk_radius = airyDiskRadius(em_wvl, NA)\n\npinhole_au = confocality(pinhole_radius_BP, airy_disk_radius)\n\noil_RI = 1.515\npz = 0\n\nX1Params_high_res_index_matched = {\n    \"nx\" : 51, # XY size of output PSF in pixels, must be odd\n    \"pz\" : pz,  # depth of point source relative to coverslip (um)\n    \"NA\" : NA, # numerical aperture\n    \"ti0\": 150,  # working distance of the objective (um)\n    \"ni\" : oil_RI, # immersion medium refractive index, experimental value\n    \"ni0\": oil_RI,  # immersion medium refractive index, design value\n    \"ex_wvl\" : ex_wvl, # excitation wavelength (um)\n    \"em_wvl\" : em_wvl, # emission wavelength (um)\n    \"ns\"   : oil_RI, # sample refractive index\n    \"pinhole_au\" : pinhole_au, # pinhole size (Airy units)\n    \"model\" : \"vectorial\",\n}\n\nPSF_fixed = plotConfocalPSF(X1Params_high_res_index_matched)\n\n\n\n\n\nNote the symmetrical nature of the axial view when things are optimal.\n\n\nImaging with an oil immersion objective, depth=2\nEven at a depth of 2 microns away from the coverslip, not much changes if the RI of the sample matches the RI of the immersion oil\n\n\nCode\nex_wvl = 0.488\nem_wvl = 0.509\npinhole_radius = 25\nmag_objective = 100\nNA = 1.49\npinhole_radius_BP = backProjectedPinholeRadius(pinhole_radius, mag_objective)\nairy_disk_radius = airyDiskRadius(em_wvl, NA)\n\npinhole_au = confocality(pinhole_radius_BP, airy_disk_radius)\n\noil_RI = 1.515\npz = 2\n\nX1Params_high_res_index_matched_2um = {\n    \"nx\" : 51, # XY size of output PSF in pixels, must be odd\n    \"pz\" : pz,  # depth of point source relative to coverslip (um)\n    \"NA\" : NA, # numerical aperture\n    \"ti0\": 150,  # working distance of the objective (um)\n    \"ni\" : oil_RI, # immersion medium refractive index, experimental value\n    \"ni0\": oil_RI,  # immersion medium refractive index, design value\n    \"ex_wvl\" : ex_wvl, # excitation wavelength (um)\n    \"em_wvl\" : em_wvl, # emission wavelength (um)\n    \"ns\"   : oil_RI, # sample refractive index\n    \"pinhole_au\" : pinhole_au, # pinhole size (Airy units)\n    \"model\" : \"vectorial\",\n}\n\nPSF_fixed_2um = plotConfocalPSF(X1Params_high_res_index_matched_2um)\n\n\n\n\n\n\n\nImaging in DMEM with an oil objective at depth = 0\nThen, let’s consider a realistic example: live-cell imaging in DMEM\n\n\nCode\nex_wvl = 0.488\nem_wvl = 0.509\npinhole_radius = 25\nmag_objective = 100\nNA = 1.49\npinhole_radius_BP = backProjectedPinholeRadius(pinhole_radius, mag_objective)\nairy_disk_radius = airyDiskRadius(em_wvl, NA)\n\npinhole_au = confocality(pinhole_radius_BP, airy_disk_radius)\n\noil_RI = 1.515\nDMEM_RI = 1.34 # DMEM with 10% FBS\npz = 0\n\nX1Params_livecell = {\n    \"nx\" : 51, # XY size of output PSF in pixels, must be odd\n    \"pz\" : pz,  # depth of point source relative to coverslip (um)\n    \"NA\" : NA, # numerical aperture\n    \"ti0\": 150,  # working distance of the objective (um)\n    \"ni\" : oil_RI, # immersion medium refractive index, experimental value\n    \"ni0\": oil_RI,  # immersion medium refractive index, design value\n    \"ex_wvl\" : ex_wvl, # excitation wavelength (um)\n    \"em_wvl\" : em_wvl, # emission wavelength (um)\n    \"ns\"   : DMEM_RI, # sample refractive index\n    \"pinhole_au\" : pinhole_au, # pinhole size (Airy units)\n    \"model\" : \"vectorial\",\n}\n\n\nPSF_livecell = plotConfocalPSF(X1Params_livecell)\n\n\n\n\n\n\n\nImaging in DMEM with an oil objective at depth = 2\nAxial resolution will deteriorate as the focus position moves away from the coverslip.\nLet’s consider imaging at a depth of two microns\n\n\nCode\nex_wvl = 0.488\nem_wvl = 0.509\npinhole_radius = 25\nmag_objective = 100\nNA = 1.49\npinhole_radius_BP = backProjectedPinholeRadius(pinhole_radius, mag_objective)\nairy_disk_radius = airyDiskRadius(em_wvl, NA)\n\npinhole_au = confocality(pinhole_radius_BP, airy_disk_radius)\n\noil_RI = 1.515\nDMEM_RI = 1.34 # DMEM with 10% FBS\npz = 2\n\nX1Params_livecell_2um = {\n    \"nx\" : 51, # XY size of output PSF in pixels, must be odd\n    \"pz\" : pz,  # depth of point source relative to coverslip (um)\n    \"NA\" : NA, # numerical aperture\n    \"ti0\": 150,  # working distance of the objective (um)\n    \"ni\" : oil_RI, # immersion medium refractive index, experimental value\n    \"ni0\": oil_RI,  # immersion medium refractive index, design value\n    \"ex_wvl\" : ex_wvl, # excitation wavelength (um)\n    \"em_wvl\" : em_wvl, # emission wavelength (um)\n    \"ns\"   : DMEM_RI, # sample refractive index\n    \"pinhole_au\" : pinhole_au, # pinhole size (Airy units)\n    \"model\" : \"vectorial\",\n}\n\n\nPSF_livecell_2um = plotConfocalPSF(X1Params_livecell_2um)\n\n\n\n\n\nNote how much worse the axial performance is from the spherical aberration induced by RI-mismatch between the sample and immersion oil!"
  },
  {
    "objectID": "posts/2023-06-13_Educational-Resources/Educational-Resources.html",
    "href": "posts/2023-06-13_Educational-Resources/Educational-Resources.html",
    "title": "Educational Resources and Tools",
    "section": "",
    "text": "For understanding digital images, image formation, and basic image processing and analysis, my all-time favorite resource has to be Pete Bankhead’s Introduction to Bioimage Analysis.\nFor more details about fluorescence microscopy, MyScope (Microscopy Austrailia) is a good resource–especially if you go through their simulators for confocal/STED microscopy.\n\nCollection of online beginner resources with content category indicated by the icons ✔️ and ❌.\n\n\nName\nSample Prep\nMicroscopy\nAnalysis1\n\n\n\n\nIntroduction to Bioimage Analysis\n❌\n✔️\n✔️\n\n\nMyScope (Microscopy Austrailia)\n❌\n✔️\n❌\n\n\nMicrocourses\n❌\n✔️\n❌\n\n\nMicroscopyU (Nikon)\n✔️\n✔️\n❌\n\n\nDesigning a rigorous microscopy experiment: Validating methods and avoiding bias\n✔️\n✔️\n✔️\n\n\nTutorial: guidance for quantitative confocal\n✔️\n✔️\n✔️\n\n\nFiji Training Notes (Cameron Nowell)\n❌\n❌\n✔️\n\n\nLecture BioImage Analysis 2020 (Robert Haase)\n❌\n❌\n✔️"
  },
  {
    "objectID": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#resources-for-beginners",
    "href": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#resources-for-beginners",
    "title": "Educational Resources and Tools",
    "section": "",
    "text": "For understanding digital images, image formation, and basic image processing and analysis, my all-time favorite resource has to be Pete Bankhead’s Introduction to Bioimage Analysis.\nFor more details about fluorescence microscopy, MyScope (Microscopy Austrailia) is a good resource–especially if you go through their simulators for confocal/STED microscopy.\n\nCollection of online beginner resources with content category indicated by the icons ✔️ and ❌.\n\n\nName\nSample Prep\nMicroscopy\nAnalysis1\n\n\n\n\nIntroduction to Bioimage Analysis\n❌\n✔️\n✔️\n\n\nMyScope (Microscopy Austrailia)\n❌\n✔️\n❌\n\n\nMicrocourses\n❌\n✔️\n❌\n\n\nMicroscopyU (Nikon)\n✔️\n✔️\n❌\n\n\nDesigning a rigorous microscopy experiment: Validating methods and avoiding bias\n✔️\n✔️\n✔️\n\n\nTutorial: guidance for quantitative confocal\n✔️\n✔️\n✔️\n\n\nFiji Training Notes (Cameron Nowell)\n❌\n❌\n✔️\n\n\nLecture BioImage Analysis 2020 (Robert Haase)\n❌\n❌\n✔️"
  },
  {
    "objectID": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#colocalization",
    "href": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#colocalization",
    "title": "Educational Resources and Tools",
    "section": "Colocalization",
    "text": "Colocalization\nColocalization is a frequent analysis request, but avoid the common pitfalls!\n\nCollection of colocalization resources\n\n\nName\nSample Prep\nMicroscopy\nAnalysis\n\n\n\n\nColocalization Analysis (ImageJ)\n❌\n❌\n✔️\n\n\nA practical guide to evaluating colocalization in biological microscopy\n❌\n❌\n✔️\n\n\nImage co-localization–co-occurrence versus correlation\n❌\n✔️\n✔️\n\n\nA localization tale\n❌\n❌\n✔️\n\n\nDeconstructing co-localisation workflows: A journey into the black boxes\n❌\n✔️\n✔️"
  },
  {
    "objectID": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#light-sheet",
    "href": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#light-sheet",
    "title": "Educational Resources and Tools",
    "section": "Light-sheet",
    "text": "Light-sheet\n\nCollection of light-sheet resources with content category indicated by the icons ✔️ and ❌.\n\n\nName\nSample Prep\nMicroscopy\nAnalysis\n\n\n\n\nTutorial: practical considerations for tissue clearing and imaging\n✔️\n✔️\n❌\n\n\nPractical considerations for quantitative light sheet fluorescence microscopy\n❌\n✔️\n✔️"
  },
  {
    "objectID": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#analysis-software-downloads-and-resources",
    "href": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#analysis-software-downloads-and-resources",
    "title": "Educational Resources and Tools",
    "section": "Analysis software downloads and resources",
    "text": "Analysis software downloads and resources\nWhile the free viewers from microscope companies can be helpful for inspecting metadata in an easy-to-parse way2, knowing how to use Fiji (or ImageJ with Bio-Formats) will be more beneficial for beginners. Most likely, you’ll need to use microscopes from different companies and also use Fiji for some processing/analysis.\n\n\n\nName\nBrief Description\nResources\n\n\n\n\nFiji\nA “batteries-included” distribution of ImageJ\nlink\n\n\nNIS-Elements Viewer\nNikon’s free standalone program for .nd2 files\n\n\n\nImaris Viewer\nFree 3D/4D image viewer (limited!)\nImaris Homeschool\n\n\nLeica LAS X Office\nFree software for viewing Leica files\n\n\n\nSVI Huygens\nDeconvolution, Visualization, Analysis\nDeconvolution video\n\n\n\n\nFiji Plugins and Macros\nExporting a .lif file to individual .tifs can be done through Fiji. One macro that does the trick can be found here. See my video instructions.\nSetting colors and adjusting brightness & contrast for multi-channel datasets can be done through BIOP Channel Tools."
  },
  {
    "objectID": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#acquisition-scope-specific",
    "href": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#acquisition-scope-specific",
    "title": "Educational Resources and Tools",
    "section": "Acquisition (scope-specific)",
    "text": "Acquisition (scope-specific)\nMy documentation for a Nikon Ti2-E with a Yokogawa CSU-X1 spinning disk unit and 405nm photostimulation capabilities can be found online.\nMy video tutorials for the Advanced Light Microscopy Core’s Leica SP8 FALCON and Leica SP8 STED 3X are on YouTube"
  },
  {
    "objectID": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#footnotes",
    "href": "posts/2023-06-13_Educational-Resources/Educational-Resources.html#footnotes",
    "title": "Educational Resources and Tools",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDue to space limitations, “Analysis” refers to both image analysis and processing.↩︎\nAnother benefit of looking at .nd2 files using NIS-Elements Viewer (as opposed to Bio-Formats) is the faster loading which is especially helpful if inspecting metadata is the sole goal.↩︎"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "I set up a website through GitHub Pages with Jekyll a while ago, but I ended up wanting to use the domain as a proof of concept for filtering microscopes based on specs. While I like Material for MkDocs and have successfully used it for hosting scope documentation for a lab spinning disk confocal microscope, I’m not yet at a point where I’d want to toss $15 / month to become an “Insider” to receive certain features.\nSurely Quarto will be what I finally settle on for a personal blog."
  },
  {
    "objectID": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html",
    "href": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html",
    "title": "Image restoration with deep learning",
    "section": "",
    "text": "A successful live-cell fluorescence microscopy experiment needs to balance spatial/temporal -resolution, sample viability, and image quality which collectively form the “pyramid of frustration”.\nIf the camera exposure time is too long, then motion blur becomes a problem. Shortening the exposure time sacrifices image quality–unless the laser power is increased1. But higher laser power leads to increased odds of phototoxicity (compromising the experiment) and photobleaching (limiting the number of useful images while contributing to phototoxicity)."
  },
  {
    "objectID": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#drcan",
    "href": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#drcan",
    "title": "Image restoration with deep learning",
    "section": "3DRCAN",
    "text": "3DRCAN\n\n\n\nFigure 1: Endoplasmic reticulum tubules before (top-right) and after denoising with 3DRCAN (bottom-left)\n\n\nWhen performing the experiments for the paper, 3DRCAN was among the state-of-the-art image restoration techniques.\nThere were two downsides to 3DRCAN which limited its use in the paper.\n\nRequires paired images (low/high quality) for training\nPotential to hallucinate at very low signal to noise ratios\n\n\nDifficulties with obtaining paired training data\nWe used an epithelial cell line (A431) stably expressing:\n\n\n\nMarker\nTagged fluorescent protein\n\n\n\n\nDesmosome\nDesmoplakin-EGFP\n\n\nER 2\nmApple-VAPB\n\n\n\nFixation3 and mounting4 conditions were carefully optimized to preserve ER integrity and cell morphology.\nmApple-VAPB’s fixation-induced brightness reduction necessitated longer exposure times and/or higher laser power. However, the spinning disk confocal microscope used to be in a room with poor temperature stability which can lead to stage/sample drift. The longer it takes to acquire a z-stack, the higher the risk of misregistration between the matching datasets which would hamper 3DRCAN performance.\nER morphology in A431 cells can be quite varied–especially as a function of mApple-VAPB expression. To ensure robustness of training data (ER morphology, mApple-VAPB expression levels), 37 datasets were used.\nOverall, obtaining training paired data was a bit of a hassle.\n\n\nArtefacts from 3DRCAN\nAlthough 3DRCAN did great with ER tubules, the restoration of ER sheet-like structures (especially in the dense perinuclear region) was a little suspect. Denoising of other fluorescence microscopy data used Noise2Void–which notably does not require paired training data."
  },
  {
    "objectID": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#footnotes",
    "href": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#footnotes",
    "title": "Image restoration with deep learning",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(and the fluorophore can handle it)↩︎\nDid you know Sec61B has reduced abundance in certain peripheral tubules?↩︎\nER is generally not well-preserved with typical chemical fixation protocols, but I didn’t know how to cryofix yet.↩︎\nWe saw more flattening with ProLong Glass than with ProLong Gold.↩︎"
  },
  {
    "objectID": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#noise2void",
    "href": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#noise2void",
    "title": "Image restoration with deep learning",
    "section": "Noise2Void",
    "text": "Noise2Void\n\n\n\n\n\n\nMax intensity projection of mApple-VAPB in A431 cells over an hour (raw)\n\n\n\n\n\n\n\nMax intensity projection of mApple-VAPB in A431 cells over an hour (with Noise2Void)"
  },
  {
    "objectID": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#noise2void-n2v",
    "href": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#noise2void-n2v",
    "title": "Image restoration with deep learning",
    "section": "Noise2Void (N2V)",
    "text": "Noise2Void (N2V)\nOne reason to like Noise2Void is that its training data can consist solely of noisy images.\nNote: Fixed pattern noise (from the sCMOS camera) is still visible after N2V, but it was dramatically reduced with 3DRCAN.\n\n\n\n\n\n\nMax intensity projection of mApple-VAPB in A431 cells over an hour (raw)\n\n\n\n\n\n\n\nMax intensity projection of mApple-VAPB in A431 cells over an hour (with Noise2Void)"
  },
  {
    "objectID": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#n2v2",
    "href": "posts/2023-08-03_techniques-in-NCB-paper/2023-08-03_Image-Restoration.html#n2v2",
    "title": "Image restoration with deep learning",
    "section": "N2V2",
    "text": "N2V2\nPrevious examples showed the power of image restoration on fluorescence microscopy datasets, but electron microscopy datasets can also be denoised!\n\n\nThe total acquisition time for one of our FIBSEM datasets took 8 days. Scope time is precious, so scanning slower is not an option. Increasing beam energy could lead to sample damage or deeper penetration–when we only want the surface.\nNoise2Void was initially applied to the Focused Ion Beam Scanning Electron Microscopy (FIBSEM) datasets, but checkerboard artefacts hindered automated segmentation of certain objects.\nFortunately during paper revisions, N2V2 became available!\nCompare between raw, Noise2Void, and N2V2 below.\n\nrawN2VN2V2\n\n\n\n\n\nSmall crop of a FIBSEM dataset with 4x4x4 nm voxels.\n\n\n\n\n\n\n\nSmall crop of a FIBSEM dataset with 4x4x4 nm voxels.\n\n\n\n\n\n\n\nSmall crop of a FIBSEM dataset with 4x4x4 nm voxels."
  }
]